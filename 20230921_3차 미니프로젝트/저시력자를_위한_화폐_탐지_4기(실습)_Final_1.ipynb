{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )\n","---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동, 데이터 다운로드\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695611916656,"user_tz":-540,"elapsed":27755,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"151efdc1-fdac-4fb4-ea37-4bb46146c345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install gdown"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sUNGwmDxAda","executionInfo":{"status":"ok","timestamp":1695611922430,"user_tz":-540,"elapsed":5776,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"0a498975-7467-441e-a0d6-9afde369fabb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkSa5ejf8LMe"},"outputs":[],"source":["import zipfile, gdown,os\n","url =\"https://drive.google.com/file/d/1k1tXDK35s6BsMTPGWSl5GVGNoPfC898X/view?usp=drive_link\"\n","file_name = \"money_dataset.zip\"\n","output = \"/content/drive/MyDrive/\" + file_name # 변경 가능\n","if not os.path.exists(output):\n","    gdown.download(url=url, output=output, quiet=False, fuzzy=True)"]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","money_data = zipfile.ZipFile(output)"],"metadata":{"id":"N4cdpkRv86QQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/Dataset/')"],"metadata":{"id":"TDAyDRLT9hZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/Dataset/images;\n","!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n","\n","!mkdir /content/Dataset/labels;\n","!mkdir /content/Dataset/labels/train; mkdir /content/Dataset/labels/val"],"metadata":{"id":"YBqCJU5z_UI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","from sklearn.model_selection import train_test_split\n","dst_train_img = '/content/Dataset/images/train'\n","dst_val_img = '/content/Dataset/images/val'\n","dst_train_label = '/content/Dataset/labels/train'\n","dst_val_label = '/content/Dataset/labels/val'\n","for won in won_list:\n","\n","    image_dir = os.path.join(data_path, won)\n","    label_dir = os.path.join(data_path, won)\n","\n","    # shutil를 사용하기 위해서 경로까지 가져오는 glob을 사용한다.\n","    file_list_img = glob.glob(os.path.join(image_dir, '*.jpg'))\n","    file_list_label = glob.glob(os.path.join(label_dir, '*.json'))\n","\n","    file_list_img.sort()\n","    file_list_label.sort()\n","\n","    print('='*30)\n","    print(won)\n","    print(len(file_list_img), len(file_list_label))\n","    train_jpg, val_jpg, train_json, val_json = train_test_split(file_list_img, file_list_label, test_size=0.2)\n","    print(len(train_jpg), len(val_jpg), len(train_json), len(val_json))\n","\n","    # .copy(소스경로, 대상경로) : 소스경로의 파일을 대상경로로 복사\n","    for jpg in train_jpg:\n","        shutil.copy(jpg, dst_train_img)\n","    for jpg in val_jpg:\n","        shutil.copy(jpg, dst_val_img)\n","    for json in train_json:\n","        shutil.copy(json, dst_train_label)\n","    for json in val_json:\n","        shutil.copy(json, dst_val_label)"],"metadata":{"id":"1qfGCSqy_kL0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695611939914,"user_tz":-540,"elapsed":3567,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"4cc90432-fa59-4f7e-bab1-d7b77cb372aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==============================\n","10\n","436 436\n","348 88 348 88\n","==============================\n","50\n","440 440\n","352 88 352 88\n","==============================\n","100\n","440 440\n","352 88 352 88\n","==============================\n","500\n","440 440\n","352 88 352 88\n","==============================\n","1000\n","858 858\n","686 172 686 172\n","==============================\n","5000\n","867 867\n","693 174 693 174\n","==============================\n","10000\n","867 867\n","693 174 693 174\n","==============================\n","50000\n","870 870\n","696 174 696 174\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/5로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/5로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json"],"metadata":{"id":"MgUoCewjM-Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/Dataset/labels/'\n","temp_list = ['train', 'val']"],"metadata":{"id":"gBD1Zv9BKaxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/Dataset/jstotxt;\n","!mkdir /content/Dataset/jstotxt/train;\n","!mkdir /content/Dataset/jstotxt/val;"],"metadata":{"id":"HZYh0HZyRoam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n","########################\n","\n","for temp in temp_list:\n","    path = os.path.join(json_path, temp)\n","    files_json = os.listdir(path)\n","    #print(len(file_json))\n","\n","    # 텍스트 파일 저장 경로 지정\n","    txt_path = '/content/Dataset/jstotxt'\n","    txt_all_path = os.path.join(txt_path, temp)\n","\n","    for js_file in files_json:\n","        js_path = os.path.join(path, js_file)\n","        with open(js_path, 'r') as f:\n","            js = json.load(f)\n","        label = js['imagePath'].split('_', 1)[0]\n","        #  {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}\n","        # label_dic = {10:0, 50:1, 100:2, 500:3, 1000:4, 5000:5, 10000:6, 50000:7}\n","        # label = label_dic[label]\n","        if label == '10':\n","            label = 0\n","        elif label == '50':\n","            label = 1\n","        elif label == '100':\n","            label = 2\n","        elif label == '500':\n","            label = 3\n","        elif label == '1000':\n","            label = 4\n","        elif label == '5000':\n","            label = 5\n","        elif label == '10000':\n","            label = 6\n","        elif label == '50000':\n","            label = 7\n","\n","        x1 = js['shapes'][0]['points'][0][0]/5\n","        y1 = js['shapes'][0]['points'][0][1]/5\n","        x2 = js['shapes'][0]['points'][1][0]/5\n","        y2 = js['shapes'][0]['points'][1][1]/5\n","\n","        x_center = (x1+x2)/2\n","        y_center = (y1+y2)/2\n","\n","        org_width = js['imageWidth']/5\n","        org_height = js['imageHeight']/5\n","\n","        width = x2-x1\n","        height = y2-y1\n","\n","        # 텍스트 파일 저장 경로와 파일명 까진 합친 경로\n","        tpath = os.path.join(txt_all_path, js_file.replace('.json', '.txt'))\n","        with open(tpath, 'w') as txt_file:\n","            txt_file.write(f'{label} {x_center/org_width} {y_center/org_height} {width/org_width} {height/org_height}')"],"metadata":{"id":"Mzh2Y8doMEK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 폴더 삭제\n","!rm -r /content/Dataset/labels/train*\n","!rm -r /content/Dataset/labels/val*\n","# 폴더 이동\n","shutil.move('/content/Dataset/jstotxt/train', '/content/Dataset/labels')\n","shutil.move('/content/Dataset/jstotxt/val', '/content/Dataset/labels')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rq_zOck2Rsxt","executionInfo":{"status":"ok","timestamp":1695611942138,"user_tz":-540,"elapsed":2226,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"c8113a81-0024-4109-97e5-80663eeb5982"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/Dataset/labels/val'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"ofZjVrcYWVbE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pu1iQfQolBhJ"},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvMQcHirmSnD"},"outputs":[],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","data = {\n","    'names': won_dict,\n","    'nc': 8,\n","    'path' : '/content/Dataset',\n","    'train': 'images/train',\n","    'val': 'images/val'\n","}\n","with open('/content/Dataset/money.yaml', 'w') as f :\n","    yaml.dump(data, f, default_flow_style=False)"]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","!pip install -r yolov5/requirements.txt  # install"],"metadata":{"id":"Biyr9AHkMyNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695611972147,"user_tz":-540,"elapsed":10306,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"035fa3d6-6c32-4ddd-ae9c-b6c6602f98b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15994, done.\u001b[K\n","remote: Counting objects: 100% (27/27), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 15994 (delta 18), reused 18 (delta 12), pack-reused 15967\u001b[K\n","Receiving objects: 100% (15994/15994), 14.58 MiB | 7.08 MiB/s, done.\n","Resolving deltas: 100% (10984/10984), done.\n","Collecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n","  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 9)) (9.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.2)\n","Collecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n","Collecting ultralytics>=8.0.147 (from -r yolov5/requirements.txt (line 18))\n","  Downloading ultralytics-8.0.186-py3-none-any.whl (618 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.4/618.4 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (16.0.6)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n","Successfully installed gitdb-4.0.10 gitpython-3.1.37 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.186\n"]}]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","/content/Dataset/money.yaml"],"metadata":{"id":"sSVIqkMLDIOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AYFDMaVfmTK"},"outputs":[],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","# !cd python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt"]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"id":"4yzf7foxpAOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"id":"grhhfC1hpHUD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = YOLO(model = 'yolov5n.yaml', task='detect')"],"metadata":{"id":"oAQtEr4Vo6rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train(data='/content/Dataset/money.yaml',\n","            epochs=10,\n","            pretrained=True,\n","            verbose=True,\n","            )"],"metadata":{"id":"TwhbHxccpS8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(source='/content/KakaoTalk_20230922_105144925.png',\n","              save=True,\n","              conf=0.1,\n","              iou=0.5,\n","              line_width=2\n","              )"],"metadata":{"id":"G3kt4InUq--e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(source='/content/Dataset/50000/50000_B_DESK_0_102.jpg',\n","              save=True,\n","              conf=0.25,\n","              iou=0.7,\n","              line_width=2\n","              )"],"metadata":{"id":"xH6dtrRa1Yd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"fJY1DeMf5xAo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/yolov5/train.py --img 640 --batch 64 --epochs 50 --data /content/Dataset/money.yaml --weights yolov5s.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtiRgd714mbw","executionInfo":{"status":"ok","timestamp":1695614298557,"user_tz":-540,"elapsed":2201942,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"e6efd404-c792-4391-fa81-c042fdab3f85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/Dataset/money.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 333MB/s]\n","\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n","  warnings.warn(\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), RandomRotate90(p=0.4), VerticalFlip(p=0.5), CLAHE(p=0.5, clip_limit=(50, 100), tile_grid_size=(70, 70)), Cutout(p=0.5, num_holes=8, max_h_size=30, max_w_size=30), Rotate(p=0.5, limit=(-90, 90), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box', crop_border=False)\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train... 4172 images, 0 backgrounds, 0 corrupt: 100% 4172/4172 [00:00<00:00, 8186.01it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 1046 images, 0 backgrounds, 0 corrupt: 100% 1046/1046 [00:00<00:00, 5086.52it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49      13.8G    0.07276    0.02578    0.05707         28        640: 100% 66/66 [00:42<00:00,  1.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:08<00:00,  1.03it/s]\n","                   all       1046       1046      0.205      0.763      0.307       0.16\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49      17.1G    0.04435    0.01631    0.04663         21        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.32it/s]\n","                   all       1046       1046      0.225       0.73      0.316      0.163\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49      17.1G    0.03929    0.01227     0.0386         24        640: 100% 66/66 [00:33<00:00,  1.95it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.20it/s]\n","                   all       1046       1046      0.483      0.818      0.684      0.416\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49      17.1G    0.03347    0.01079    0.02795         21        640: 100% 66/66 [00:34<00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.22it/s]\n","                   all       1046       1046      0.446      0.736      0.579      0.395\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49      17.1G    0.03024    0.01019    0.02501         26        640: 100% 66/66 [00:35<00:00,  1.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.26it/s]\n","                   all       1046       1046      0.582      0.849      0.727      0.494\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49      17.1G     0.0271   0.009712    0.02387         23        640: 100% 66/66 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.37it/s]\n","                   all       1046       1046      0.647      0.889      0.745      0.571\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49      17.1G     0.0258   0.009047    0.02318         26        640: 100% 66/66 [00:33<00:00,  1.97it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.24it/s]\n","                   all       1046       1046      0.629      0.913      0.746      0.598\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49      17.1G    0.02425    0.00857    0.02181         19        640: 100% 66/66 [00:38<00:00,  1.74it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.41it/s]\n","                   all       1046       1046      0.736      0.841      0.785      0.645\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49      17.1G    0.02313   0.008476     0.0204         24        640: 100% 66/66 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.26it/s]\n","                   all       1046       1046      0.698      0.842      0.788      0.652\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49      17.1G    0.02261    0.00826    0.02026         23        640: 100% 66/66 [00:36<00:00,  1.79it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.40it/s]\n","                   all       1046       1046      0.732      0.868      0.815      0.691\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49      17.1G    0.02167   0.008103    0.01993         29        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.33it/s]\n","                   all       1046       1046      0.803      0.916      0.834      0.707\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49      17.1G    0.02089   0.007843    0.01881         28        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.33it/s]\n","                   all       1046       1046       0.79      0.924       0.86      0.728\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49      17.1G     0.0204   0.007786    0.01804         24        640: 100% 66/66 [00:34<00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.26it/s]\n","                   all       1046       1046      0.775        0.9      0.867      0.755\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49      17.1G    0.02007   0.007442    0.01809         22        640: 100% 66/66 [00:33<00:00,  1.99it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.13it/s]\n","                   all       1046       1046      0.776      0.913      0.886      0.741\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49      17.1G    0.01917   0.007429    0.01621         36        640: 100% 66/66 [00:35<00:00,  1.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.31it/s]\n","                   all       1046       1046      0.873       0.88      0.906      0.798\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49      17.1G    0.01902   0.007251    0.01645         21        640: 100% 66/66 [00:37<00:00,  1.78it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.48it/s]\n","                   all       1046       1046      0.828      0.902      0.916      0.813\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49      17.1G     0.0186   0.007032    0.01596         22        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.28it/s]\n","                   all       1046       1046      0.863      0.915      0.933      0.837\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49      17.1G     0.0183   0.006956    0.01609         23        640: 100% 66/66 [00:36<00:00,  1.80it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.45it/s]\n","                   all       1046       1046      0.855      0.895      0.925      0.829\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49      17.1G    0.01779   0.007063     0.0152         25        640: 100% 66/66 [00:35<00:00,  1.86it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.25it/s]\n","                   all       1046       1046      0.917      0.917      0.955      0.865\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49      17.1G    0.01743   0.006821    0.01498         24        640: 100% 66/66 [00:34<00:00,  1.93it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.25it/s]\n","                   all       1046       1046       0.93      0.915      0.953       0.86\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49      17.1G    0.01719   0.006758    0.01398         25        640: 100% 66/66 [00:36<00:00,  1.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.34it/s]\n","                   all       1046       1046      0.916      0.923      0.951      0.838\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49      17.1G    0.01688   0.006672    0.01391         21        640: 100% 66/66 [00:33<00:00,  1.95it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.27it/s]\n","                   all       1046       1046       0.91       0.92      0.955      0.851\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49      17.1G    0.01678   0.006682    0.01418         24        640: 100% 66/66 [00:34<00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.24it/s]\n","                   all       1046       1046      0.949      0.932      0.969      0.886\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49      17.1G    0.01585   0.006493    0.01302         17        640: 100% 66/66 [00:35<00:00,  1.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.36it/s]\n","                   all       1046       1046      0.927      0.923      0.957      0.879\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49      17.1G    0.01569   0.006351    0.01252         21        640: 100% 66/66 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.26it/s]\n","                   all       1046       1046      0.965      0.928      0.972      0.894\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49      17.1G    0.01523     0.0063    0.01228         23        640: 100% 66/66 [00:35<00:00,  1.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.31it/s]\n","                   all       1046       1046      0.904      0.917      0.953      0.883\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49      17.1G    0.01496   0.006211    0.01184         21        640: 100% 66/66 [00:36<00:00,  1.82it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.34it/s]\n","                   all       1046       1046      0.928      0.885      0.943      0.873\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49      17.1G    0.01496   0.006082     0.0114         22        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.27it/s]\n","                   all       1046       1046      0.948      0.972      0.986      0.923\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49      17.1G    0.01444    0.00612     0.0113         20        640: 100% 66/66 [00:33<00:00,  1.95it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.19it/s]\n","                   all       1046       1046      0.937      0.953      0.982      0.926\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49      17.1G    0.01449   0.005848    0.01084         30        640: 100% 66/66 [00:34<00:00,  1.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.22it/s]\n","                   all       1046       1046       0.95      0.956      0.985       0.94\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49      17.1G    0.01465   0.006106    0.01052         24        640: 100% 66/66 [00:34<00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.27it/s]\n","                   all       1046       1046       0.98      0.974       0.99      0.929\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49      17.1G    0.01425   0.005817    0.01043         22        640: 100% 66/66 [00:35<00:00,  1.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.30it/s]\n","                   all       1046       1046      0.976      0.976      0.988      0.944\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49      17.1G    0.01388   0.005898    0.01066         29        640: 100% 66/66 [00:35<00:00,  1.86it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.27it/s]\n","                   all       1046       1046       0.97      0.959      0.986      0.943\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/49      17.1G    0.01318   0.005798    0.01004         28        640: 100% 66/66 [00:34<00:00,  1.93it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.19it/s]\n","                   all       1046       1046      0.978      0.976      0.991      0.953\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/49      17.1G    0.01305   0.005714   0.009743         21        640: 100% 66/66 [00:34<00:00,  1.93it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.26it/s]\n","                   all       1046       1046      0.972      0.982      0.992      0.957\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/49      17.1G    0.01314   0.005683   0.008716         24        640: 100% 66/66 [00:37<00:00,  1.77it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:05<00:00,  1.52it/s]\n","                   all       1046       1046      0.985      0.976      0.992      0.958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/49      17.1G    0.01235   0.005483   0.008829         34        640: 100% 66/66 [00:33<00:00,  1.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.31it/s]\n","                   all       1046       1046      0.991      0.963      0.992      0.965\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/49      17.1G    0.01273   0.005654    0.00933         35        640: 100% 66/66 [00:34<00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.23it/s]\n","                   all       1046       1046      0.988      0.975      0.991      0.956\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/49      17.1G    0.01206    0.00532   0.008084         25        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.30it/s]\n","                   all       1046       1046      0.988      0.989      0.994       0.97\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/49      17.1G    0.01229    0.00544   0.008635         28        640: 100% 66/66 [00:34<00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.22it/s]\n","                   all       1046       1046      0.983      0.967      0.991      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/49      17.1G    0.01168   0.005258    0.00759         31        640: 100% 66/66 [00:36<00:00,  1.81it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.33it/s]\n","                   all       1046       1046      0.983      0.983      0.992      0.971\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/49      17.1G    0.01158   0.005092   0.007635         25        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.32it/s]\n","                   all       1046       1046      0.986      0.987      0.993      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/49      17.1G    0.01126   0.005039   0.007367         26        640: 100% 66/66 [00:37<00:00,  1.78it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.50it/s]\n","                   all       1046       1046      0.986      0.983      0.993      0.973\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/49      17.1G    0.01088   0.005022   0.007162         26        640: 100% 66/66 [00:34<00:00,  1.94it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.31it/s]\n","                   all       1046       1046      0.993      0.982      0.992      0.972\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/49      17.1G    0.01076   0.005024   0.006954         29        640: 100% 66/66 [00:34<00:00,  1.91it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.22it/s]\n","                   all       1046       1046      0.987       0.99      0.993      0.976\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/49      17.1G     0.0105   0.004779   0.006688         21        640: 100% 66/66 [00:33<00:00,  1.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.14it/s]\n","                   all       1046       1046      0.991      0.991      0.993      0.977\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/49      17.1G    0.01047   0.004821   0.006379         27        640: 100% 66/66 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.24it/s]\n","                   all       1046       1046      0.995      0.995      0.994      0.977\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/49      17.1G    0.01025   0.004785    0.00663         23        640: 100% 66/66 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:06<00:00,  1.30it/s]\n","                   all       1046       1046      0.996      0.986      0.993      0.983\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/49      17.1G   0.009821   0.004798   0.006211         32        640: 100% 66/66 [00:35<00:00,  1.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.27it/s]\n","                   all       1046       1046      0.994       0.99      0.993      0.979\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/49      17.1G   0.009488    0.00463   0.005707         28        640: 100% 66/66 [00:33<00:00,  1.96it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:07<00:00,  1.22it/s]\n","                   all       1046       1046      0.993      0.993      0.994      0.983\n","\n","50 epochs completed in 0.595 hours.\n","Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.4MB\n","Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.4MB\n","\n","Validating yolov5/runs/train/exp2/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 9/9 [00:09<00:00,  1.04s/it]\n","                   all       1046       1046      0.996      0.986      0.993      0.983\n","                    10       1046         88      0.999          1      0.995      0.978\n","                    50       1046         88      0.996          1      0.995      0.987\n","                   100       1046         88      0.976      0.935      0.989      0.979\n","                   500       1046         88      0.998      0.955      0.989      0.975\n","                  1000       1046        172          1          1      0.995      0.982\n","                  5000       1046        174          1          1      0.995      0.989\n","                 10000       1046        174      0.999          1      0.995      0.989\n","                 50000       1046        174      0.999          1      0.995      0.989\n","Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --source /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team --conf 0.75 --iou 0.25 --imgsz 640;"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pP_9xv3pmcmx","executionInfo":{"status":"ok","timestamp":1695615701427,"user_tz":-540,"elapsed":113434,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"e17ad896-88ab-4a00-9a89-8235e8bc84f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/drive/MyDrive/Mini_Project3/mini3_test_set_2team, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.75, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/001.jpeg: 480x640 1 100, 2 500s, 84.2ms\n","image 2/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/002.jpeg: 480x640 1 1000, 1 10000, 1 50000, 6.9ms\n","image 3/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/003.jpeg: 480x640 1 1000, 1 5000, 1 10000, 1 50000, 6.8ms\n","image 4/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/004.jpeg: 480x640 3 1000s, 3 10000s, 1 50000, 6.4ms\n","image 5/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/005.jpeg: 480x640 2 1000s, 6.7ms\n","image 6/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/006.jpeg: 480x640 1 50, 1 10000, 1 50000, 6.7ms\n","image 7/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/007.jpeg: 480x640 1 1000, 1 10000, 7.0ms\n","image 8/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/008.jpeg: 480x640 1 1000, 6.6ms\n","image 9/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/009.jpeg: 480x640 1 10000, 6.5ms\n","image 10/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/010.jpeg: 640x480 1 5000, 1 10000, 85.3ms\n","image 11/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/011.jpeg: 640x480 1 1000, 6.6ms\n","image 12/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/012.jpeg: 640x480 1 5000, 7.8ms\n","image 13/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/013.jpeg: 640x480 1 500, 1 50000, 6.5ms\n","image 14/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/014.jpeg: 640x480 1 100, 2 500s, 6.5ms\n","image 15/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/015.jpeg: 480x640 1 10000, 1 50000, 6.9ms\n","image 16/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/016.jpeg: 640x480 1 5000, 1 10000, 6.8ms\n","image 17/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/017.jpeg: 640x480 1 1000, 1 5000, 7.2ms\n","image 18/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/018.jpeg: 640x480 1 5000, 1 10000, 7.1ms\n","image 19/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/019.jpeg: 640x480 1 50000, 6.3ms\n","image 20/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/020.jpeg: 640x480 1 50000, 7.1ms\n","image 21/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/021.jpeg: 640x480 (no detections), 6.9ms\n","image 22/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/022.jpeg: 640x480 1 50000, 6.4ms\n","image 23/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/023.jpeg: 640x480 1 5000, 6.9ms\n","image 24/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/024.jpeg: 640x480 1 5000, 1 10000, 6.4ms\n","image 25/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/025.jpeg: 640x480 1 10000, 1 50000, 7.0ms\n","image 26/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/026.jpeg: 640x480 1 10000, 1 50000, 6.4ms\n","image 27/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/027.jpeg: 640x480 1 10000, 6.6ms\n","image 28/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/028.jpeg: 640x480 1 5000, 1 10000, 6.4ms\n","image 29/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/029.jpeg: 640x480 1 10000, 1 50000, 6.9ms\n","image 30/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/030.jpeg: 640x480 1 50, 1 10000, 1 50000, 6.3ms\n","image 31/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/031.jpeg: 480x640 1 10000, 1 50000, 7.0ms\n","image 32/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/032.jpeg: 640x480 1 5000, 1 10000, 6.8ms\n","image 33/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/033.jpeg: 640x480 1 50000, 7.4ms\n","image 34/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/034.jpeg: 640x480 1 5000, 1 50000, 6.5ms\n","image 35/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/035.jpeg: 640x480 (no detections), 6.8ms\n","image 36/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/036.jpeg: 640x480 1 5000, 6.4ms\n","image 37/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/037.jpeg: 640x480 1 100, 6.3ms\n","image 38/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/038.jpeg: 640x480 1 500, 7.1ms\n","image 39/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/039.jpeg: 480x640 1 10000, 6.8ms\n","image 40/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/040.jpeg: 480x640 1 10000, 1 50000, 6.4ms\n","image 41/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/041.jpeg: 640x480 1 1000, 1 5000, 7.4ms\n","image 42/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/042.jpeg: 640x480 1 1000, 1 10000, 6.8ms\n","image 43/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/043.jpeg: 640x480 1 1000, 1 50000, 7.9ms\n","image 44/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/044.jpeg: 640x480 1 1000, 1 50000, 6.6ms\n","image 45/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/045.jpeg: 640x480 1 1000, 1 5000, 1 10000, 1 50000, 7.0ms\n","Speed: 0.6ms pre-process, 10.2ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/detect/exp2\u001b[0m\n"]}]},{"cell_type":"code","source":["!cp -r /content/yolov5/runs/detect/exp2 /content/drive/MyDrive/Mini_Project3"],"metadata":{"id":"aJvEQTbayPbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --source /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team --conf 0.25 --iou 0.75 --imgsz 640;"],"metadata":{"id":"OOB31gS3z5Mw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695615974340,"user_tz":-540,"elapsed":22964,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"efa52c57-7bcf-4913-b874-d51a7b9cb1fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/drive/MyDrive/Mini_Project3/mini3_test_set_2team, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.75, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/001.jpeg: 480x640 2 100s, 2 500s, 86.4ms\n","image 2/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/002.jpeg: 480x640 2 1000s, 1 10000, 1 50000, 6.6ms\n","image 3/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/003.jpeg: 480x640 1 1000, 1 5000, 1 10000, 1 50000, 6.6ms\n","image 4/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/004.jpeg: 480x640 4 1000s, 1 5000, 4 10000s, 1 50000, 6.7ms\n","image 5/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/005.jpeg: 480x640 2 1000s, 1 5000, 1 10000, 6.8ms\n","image 6/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/006.jpeg: 480x640 2 50s, 1 5000, 1 10000, 1 50000, 6.5ms\n","image 7/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/007.jpeg: 480x640 1 1000, 1 10000, 6.5ms\n","image 8/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/008.jpeg: 480x640 1 1000, 1 50000, 6.6ms\n","image 9/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/009.jpeg: 480x640 1 100, 1 5000, 1 10000, 6.5ms\n","image 10/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/010.jpeg: 640x480 1 1000, 1 5000, 1 10000, 85.1ms\n","image 11/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/011.jpeg: 640x480 1 1000, 6.6ms\n","image 12/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/012.jpeg: 640x480 1 50, 2 500s, 1 5000, 1 10000, 7.0ms\n","image 13/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/013.jpeg: 640x480 2 100s, 1 500, 1 50000, 6.7ms\n","image 14/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/014.jpeg: 640x480 1 50, 2 100s, 2 500s, 7.4ms\n","image 15/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/015.jpeg: 480x640 1 10000, 1 50000, 7.9ms\n","image 16/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/016.jpeg: 640x480 1 50, 1 1000, 1 5000, 1 10000, 7.0ms\n","image 17/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/017.jpeg: 640x480 1 50, 1 1000, 1 5000, 1 10000, 6.5ms\n","image 18/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/018.jpeg: 640x480 1 1000, 1 5000, 1 10000, 1 50000, 6.5ms\n","image 19/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/019.jpeg: 640x480 1 1000, 1 50000, 7.2ms\n","image 20/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/020.jpeg: 640x480 1 10000, 1 50000, 6.5ms\n","image 21/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/021.jpeg: 640x480 (no detections), 6.5ms\n","image 22/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/022.jpeg: 640x480 1 1000, 1 50000, 6.4ms\n","image 23/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/023.jpeg: 640x480 1 1000, 1 5000, 1 10000, 6.5ms\n","image 24/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/024.jpeg: 640x480 1 1000, 1 5000, 1 10000, 1 50000, 6.5ms\n","image 25/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/025.jpeg: 640x480 1 10000, 1 50000, 6.6ms\n","image 26/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/026.jpeg: 640x480 1 5000, 1 10000, 1 50000, 6.5ms\n","image 27/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/027.jpeg: 640x480 1 10000, 6.5ms\n","image 28/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/028.jpeg: 640x480 1 5000, 1 10000, 6.6ms\n","image 29/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/029.jpeg: 640x480 1 50, 1 10000, 1 50000, 6.9ms\n","image 30/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/030.jpeg: 640x480 1 50, 1 10000, 1 50000, 7.2ms\n","image 31/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/031.jpeg: 480x640 1 10, 2 50s, 1 10000, 1 50000, 7.2ms\n","image 32/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/032.jpeg: 640x480 1 1000, 1 5000, 1 10000, 7.0ms\n","image 33/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/033.jpeg: 640x480 1 50000, 6.6ms\n","image 34/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/034.jpeg: 640x480 1 5000, 1 50000, 6.5ms\n","image 35/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/035.jpeg: 640x480 1 500, 2 50000s, 6.4ms\n","image 36/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/036.jpeg: 640x480 1 5000, 6.6ms\n","image 37/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/037.jpeg: 640x480 1 100, 6.4ms\n","image 38/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/038.jpeg: 640x480 1 500, 6.4ms\n","image 39/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/039.jpeg: 480x640 1 5000, 2 10000s, 1 50000, 6.9ms\n","image 40/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/040.jpeg: 480x640 1 5000, 1 10000, 1 50000, 6.4ms\n","image 41/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/041.jpeg: 640x480 1 100, 1 500, 1 1000, 1 5000, 7.0ms\n","image 42/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/042.jpeg: 640x480 1 1000, 1 10000, 6.4ms\n","image 43/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/043.jpeg: 640x480 1 1000, 1 50000, 6.7ms\n","image 44/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/044.jpeg: 640x480 1 500, 1 1000, 1 10000, 1 50000, 6.6ms\n","image 45/45 /content/drive/MyDrive/Mini_Project3/mini3_test_set_2team/045.jpeg: 640x480 1 1000, 1 5000, 1 10000, 1 50000, 7.3ms\n","Speed: 0.6ms pre-process, 10.2ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/detect/exp3\u001b[0m\n"]}]},{"cell_type":"code","source":["!cp -r /content/yolov5/runs/detect/exp3 /content/drive/MyDrive/Mini_Project3"],"metadata":{"id":"iDXKJzFLle4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkPxTZQtlsIg","executionInfo":{"status":"ok","timestamp":1695620729963,"user_tz":-540,"elapsed":893,"user":{"displayName":"안진수","userId":"12832366277133793945"}},"outputId":"fb982f5f-9c38-46a4-9b8f-206874aeb8ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JZceP3X7qvb3"},"execution_count":null,"outputs":[]}]}