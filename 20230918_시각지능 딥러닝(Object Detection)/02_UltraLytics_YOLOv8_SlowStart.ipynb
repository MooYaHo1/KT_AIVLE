{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# UltraLytics YOLO v8 일단 해보기"],"metadata":{"id":"y77rjxmifUYb"}},{"cell_type":"markdown","source":["## 라이브러리 설치"],"metadata":{"id":"C3MIWg-ffakF"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2VqF-_g4fDbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093353440,"user_tz":-540,"elapsed":6758,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"d91b6049-9947-44c3-d39d-107e2099f1ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.181-py3-none-any.whl (617 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.1/617.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.2)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (16.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: ultralytics\n","Successfully installed ultralytics-8.0.181\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"markdown","source":["## 라이브러리 불러오기"],"metadata":{"id":"g9YerUoHfpjU"}},{"cell_type":"markdown","source":["### YOLO v8 설정"],"metadata":{"id":"MONUUTFefzfU"}},{"cell_type":"code","source":["from ultralytics import settings"],"metadata":{"id":"xDtljGYcfent","executionInfo":{"status":"ok","timestamp":1695093358448,"user_tz":-540,"elapsed":5011,"user":{"displayName":"안진수","userId":"10784970127821485501"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["settings"],"metadata":{"id":"Bq6OKD-RfuUE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093358449,"user_tz":-540,"elapsed":9,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"7e1c874e-0450-4246-f5da-de45d14290c5"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'settings_version': '0.0.4',\n"," 'datasets_dir': '/content/datasets',\n"," 'weights_dir': 'weights',\n"," 'runs_dir': 'runs',\n"," 'uuid': '569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb',\n"," 'sync': True,\n"," 'api_key': '',\n"," 'clearml': True,\n"," 'comet': True,\n"," 'dvc': True,\n"," 'hub': True,\n"," 'mlflow': True,\n"," 'neptune': True,\n"," 'raytune': True,\n"," 'tensorboard': True,\n"," 'wandb': True}"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### YOLO v8 모델"],"metadata":{"id":"uZmU3hRJf2iT"}},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"id":"igXdjeXAf8zG","executionInfo":{"status":"ok","timestamp":1695093358449,"user_tz":-540,"elapsed":7,"user":{"displayName":"안진수","userId":"10784970127821485501"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["YOLO"],"metadata":{"id":"VZIudS1Pf-qd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093358449,"user_tz":-540,"elapsed":6,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"b77d0ac8-569d-407a-b0c3-32797488fe5b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ultralytics.models.yolo.model.YOLO"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## 모델링"],"metadata":{"id":"CzFyJcPwgKcM"}},{"cell_type":"markdown","source":["### 모델 선언\n","\n","- 모델의 구조와 해당 구조에 맞게 사전 학습된 가중치를 불러온다.\n","- Parameters\n","    1. model : 모델 구조 또는 모델 구조 + 가중치 설정. task와 맞는 모델을 선택해야 한다.\n","    2. task : detect, segment, classify, pose 중 택일"],"metadata":{"id":"hoEObB13gOAb"}},{"cell_type":"code","source":["model = YOLO(model='yolov8n.pt', task='detect')"],"metadata":{"id":"YsZMgUoWgJzu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093359494,"user_tz":-540,"elapsed":1050,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"4a065b11-4043-45ae-9c7e-2170e6e80679"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n","100%|██████████| 6.23M/6.23M [00:00<00:00, 120MB/s]\n"]}]},{"cell_type":"markdown","source":["### 모델 학습\n","\n","- Parameters\n","    1. data : 학습시킬 데이터셋의 경로. default 'coco128.yaml'\n","    2. epochs : 학습 데이터 전체를 총 몇 번씩 학습시킬 것인지 설정. default 100\n","    3. patience : 학습 과정에서 성능 개선이 발생하지 않을 때 몇 epoch 더 지켜볼 것인지 설정. default 50\n","    4. batch : 미니 배치의 사이즈 설정. default 16. -1일 경우 자동 설정.\n","    5. imgsz : 입력 이미지의 크기. default 640\n","    6. save : 학습 과정을 저장할 것인지 설정. default True\n","    7. project : 학습 과정이 저장되는 폴더의 이름.\n","    8. name : project 내부에 생성되는 폴더의 이름.\n","    9. exist_ok : 동일한 이름의 폴더가 있을 때 덮어씌울 것인지 설정. default False\n","    10. pretrained : 사전 학습된 모델을 사용할 것인지 설정. default False\n","    11. optimizer : 경사 하강법의 세부 방법 설정. default 'auto'\n","    12. verbose : 학습 과정을 상세하게 출력할 것인지 설정. default False\n","    13. seed : 재현성을 위한 난수 설정\n","    14. resume : 마지막 학습부터 다시 학습할 것인지 설정. default False\n","    15. freeze : 첫 레이어부터 몇 레이어까지 기존 가중치를 유지할 것인지 설정. default None"],"metadata":{"id":"8LZEcWv2gi2T"}},{"cell_type":"code","source":["model.train(data='coco128.yaml',\n","            epochs=10,\n","            patience=5,\n","            save=True,\n","            project='trained',\n","            name='trained_model',\n","            exist_ok=False,\n","            pretrained=False,\n","            optimizer='auto',\n","            verbose=False,\n","            seed=2023,\n","            resume=False,\n","            freeze=None\n","            )"],"metadata":{"id":"RBcILh6IgUSt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093462581,"user_tz":-540,"elapsed":102421,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"81fd31c4-1496-4222-b1f2-8ed8c0461466"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.181 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=10, patience=5, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=trained, name=trained_model, exist_ok=False, pretrained=False, optimizer=auto, verbose=False, seed=2023, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=trained/trained_model\n","\n","Dataset 'coco128.yaml' images not found ⚠️, missing path '/content/datasets/coco128/images/train2017'\n","Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n","100%|██████████| 6.66M/6.66M [00:00<00:00, 108MB/s]\n","Unzipping /content/datasets/coco128.zip to /content/datasets/coco128...: 100%|██████████| 263/263 [00:00<00:00, 2995.93file/s]\n","Dataset download success ✅ (0.9s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100%|██████████| 755k/755k [00:00<00:00, 26.5MB/s]\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n","Model summary: 225 layers, 3157200 parameters, 3157184 gradients\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir trained/trained_model', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<00:00, 1717.73it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n","Plotting labels to trained/trained_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mtrained/trained_model\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.79G      1.153      1.397      1.193         81        640: 100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n","                   all        128        929      0.667      0.507      0.581      0.428\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.58G       1.14      1.335      1.199        121        640: 100%|██████████| 8/8 [00:02<00:00,  3.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.12it/s]\n","                   all        128        929      0.679      0.513      0.605      0.445\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10       2.5G      1.142      1.242      1.172        108        640: 100%|██████████| 8/8 [00:01<00:00,  4.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","                   all        128        929      0.675      0.533      0.622      0.458\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.55G      1.153      1.289       1.18        116        640: 100%|██████████| 8/8 [00:01<00:00,  4.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]\n","                   all        128        929      0.667       0.57      0.649      0.477\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.58G      1.165      1.224      1.205         68        640: 100%|██████████| 8/8 [00:01<00:00,  4.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.89it/s]\n","                   all        128        929      0.655      0.587      0.663      0.495\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.54G      1.143      1.226      1.181         95        640: 100%|██████████| 8/8 [00:01<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.85it/s]\n","                   all        128        929      0.648      0.604      0.674        0.5\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.53G      1.135      1.208      1.184        115        640: 100%|██████████| 8/8 [00:01<00:00,  4.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.70it/s]\n","                   all        128        929      0.643       0.66      0.687      0.512\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.55G      1.112      1.187      1.175         71        640: 100%|██████████| 8/8 [00:01<00:00,  4.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n","                   all        128        929      0.657      0.656      0.695      0.515\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10       2.5G      1.116      1.123      1.151        142        640: 100%|██████████| 8/8 [00:01<00:00,  4.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n","                   all        128        929       0.69       0.65      0.705      0.522\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10       2.5G      1.086       1.13      1.174        104        640: 100%|██████████| 8/8 [00:01<00:00,  4.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]\n","                   all        128        929      0.683      0.654      0.705      0.523\n","\n","10 epochs completed in 0.015 hours.\n","Optimizer stripped from trained/trained_model/weights/last.pt, 6.5MB\n","Optimizer stripped from trained/trained_model/weights/best.pt, 6.5MB\n","\n","Validating trained/trained_model/weights/best.pt...\n","Ultralytics YOLOv8.0.181 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3151904 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n","                   all        128        929      0.687      0.651      0.706      0.524\n","Speed: 1.3ms preprocess, 4.3ms inference, 0.0ms loss, 3.3ms postprocess per image\n","Results saved to \u001b[1mtrained/trained_model\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e39c8e0dab0>\n","fitness: 0.5419316392777268\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.56691,     0.32258,     0.18608,     0.72636,     0.75033,      0.5942,     0.78056,     0.37442,     0.36557,     0.14562,     0.52367,      0.6469,     0.52367,     0.50381,     0.66568,      0.7343,      0.7407,     0.46399,     0.52367,     0.52367,     0.71463,       0.995,     0.97177,     0.76432,\n","           0.30574,     0.45009,     0.16407,     0.48609,     0.67174,     0.68884,     0.44775,     0.55899,      0.3591,     0.17781,     0.26401,     0.31746,     0.44566,     0.52367,     0.30314,     0.26453,     0.34383,     0.32861,     0.22388,     0.40366,     0.24015,     0.59743,    0.055603,     0.52367,\n","             0.995,     0.62391,     0.25599,      0.4982,     0.94555,     0.88219,     0.84721,     0.88999,      0.3055,      0.6523,     0.54871,     0.83008,     0.44027,     0.94564,     0.89575,     0.73794,   0.0032136,       0.525,     0.52367,    0.049652,     0.80748,     0.32877,     0.52367,     0.23447,\n","           0.62712,     0.24062,     0.77057,     0.79513,      0.2587,     0.51202,     0.52367,     0.62155])\n","names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.6870512381904973, 'metrics/recall(B)': 0.6514519528206493, 'metrics/mAP50(B)': 0.7063013435203038, 'metrics/mAP50-95(B)': 0.5236683388063293, 'fitness': 0.5419316392777268}\n","save_dir: PosixPath('trained/trained_model')\n","speed: {'preprocess': 1.252397894859314, 'inference': 4.251416772603989, 'loss': 0.0024531036615371704, 'postprocess': 3.31946462392807}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### 모델 검증"],"metadata":{"id":"PkWUIsdHmGlm"}},{"cell_type":"code","source":["model.val()"],"metadata":{"id":"hNFaK8ExgUV8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695093477843,"user_tz":-540,"elapsed":15273,"user":{"displayName":"안진수","userId":"10784970127821485501"}},"outputId":"30af2716-403c-43ea-8f5a-e0deedc34a6a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.181 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3151904 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n","                   all        128        929      0.671      0.638      0.697       0.52\n","Speed: 4.3ms preprocess, 13.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n","Results saved to \u001b[1mtrained/trained_model2\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e39a3f3b1c0>\n","fitness: 0.537700582610633\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.56698,     0.31681,     0.18578,     0.71039,     0.75028,     0.59992,     0.78057,     0.35968,     0.29002,     0.14407,     0.52004,     0.64689,     0.52004,     0.50376,     0.65865,     0.69931,     0.74338,     0.46399,     0.52004,     0.52004,     0.71429,       0.995,     0.97163,     0.76384,\n","           0.29555,     0.44626,     0.16177,     0.50435,     0.67174,     0.65477,     0.44775,     0.56098,     0.32674,     0.17099,     0.21871,     0.33179,     0.42617,     0.52004,     0.31912,     0.26142,     0.34299,     0.33687,     0.21263,     0.41512,     0.23976,      0.6059,    0.043354,     0.52004,\n","             0.995,     0.62395,     0.25517,     0.48522,       0.995,     0.86634,     0.84725,      0.9045,     0.30303,     0.67394,     0.53767,     0.79736,     0.43921,     0.94567,     0.89572,     0.69831,   0.0032704,      0.5305,     0.52004,    0.048464,     0.78362,     0.32891,     0.52004,     0.26087,\n","           0.61249,     0.23624,     0.75818,     0.79514,     0.27362,     0.50389,     0.52004,     0.66438])\n","names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.6708306218883197, 'metrics/recall(B)': 0.6378212227423778, 'metrics/mAP50(B)': 0.6966441456981847, 'metrics/mAP50-95(B)': 0.5200401867120161, 'fitness': 0.537700582610633}\n","save_dir: PosixPath('trained/trained_model2')\n","speed: {'preprocess': 4.276059567928314, 'inference': 13.327253982424736, 'loss': 0.0016316771507263184, 'postprocess': 3.8530901074409485}"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### 예측값 생성\n","- Parameters\n","    1. source : 예측 대상 이미지/동영상의 경로\n","    2. conf : confidence score threshold. default 0.25\n","    3. iou : NMS에 적용되는 IoU threshold. default 0.7. threshold를 넘기면 같은 object를 가리키는 거라고 판단.\n","    4. save : 예측된 이미지/동영상을 저장할 것인지 설정. default False\n","    5. save_txt : Annotation 정보도 함께 저장할 것인지 설정. default False\n","    6. save_conf : Annotation 정보 맨 끝에 Confidence Score도 추가할 것인지 설정. default False\n","    7. line_width : 그려지는 박스의 두께 설정. default None"],"metadata":{"id":"CwexfV6JgUYz"}},{"cell_type":"code","source":[],"metadata":{"id":"W3Y7sfzkgUcK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZhupHw96gUfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y3JbWuu6gUh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BZuviDJDgUkm"},"execution_count":null,"outputs":[]}]}